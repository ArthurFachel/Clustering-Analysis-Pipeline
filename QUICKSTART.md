# Quick Start Guide

Comece a usar o Clustering Analysis Pipeline em 5 minutos!

## ‚ö° Instala√ß√£o R√°pida

### 1. Clone e Setup
```bash
git clone https://github.com/ArthurFachel/Clustering-Analysis-Pipeline.git
cd Clustering-Analysis-Pipeline

# Crie environment Python
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

pip install -r requirements.txt
```

### 2. Configure Vari√°veis de Ambiente
```bash
cp .env.example .env
# Edite o arquivo .env com seus caminhos
```

### 3. Execute!
```bash
jupyter notebook Clustering_Analysis_Pipeline.ipynb
```

---

## üéØ Seus Primeiros Clusters em Minutos

### Op√ß√£o A: Usando Jupyter Notebook (Recomendado)

```python
from utils.run import kmeans_model
import os
from dotenv import load_dotenv

load_dotenv()

df, model = kmeans_model(chosen_k=5)

# Veja os resultados
print(df.head())
print(f"Total de pontos: {len(df)}")
print(f"Clusters: {df['cluster'].unique()}")
```

### Op√ß√£o B: Comparar Todos os M√©todos

```python
from utils.run import (
    kmeans_model,
    hierarchical_clustering_bottom_top,
    hierarchical_clustering_top_bottom
)

results = {
    "K-Means": kmeans_model(5),
    "Hierarchical (Bottom-Top)": hierarchical_clustering_bottom_top(5),
    "Hierarchical (Top-Down)": hierarchical_clustering_top_bottom(5),
}

# Analise os resultados
for name, (df, model) in results.items():
    print(f"{name}: {len(df)} pontos classificados")
```

### Op√ß√£o C: Avaliar Modelos

```python
from utils.evaluation import evaluate_kmeans
from utils.aglomerar import aglomerar

# Agregar dados de m√∫ltiplos modelos
df_agregado = aglomerar("/path/to/model/results")

# Avaliar com K=5 clusters
results = evaluate_kmeans(models_folder="/path/to/models", i=5)

# Salvar resultados
results.to_csv("evaluation_kmeans_5.csv", index=False)
print("‚úÖ Resultados salvos em evaluation_kmeans_5.csv")
```

---

## üìä Estrutura dos Dados

### Dados de Entrada (JSON)
```json
{
  "qa": {
    "question": ["O que √© ML?", "Como treinar um modelo?"],
    "answer": ["Machine Learning...", "Voc√™ precisa de dados..."],
    "task": "qa"
  },
  "tf": {
    "question": ["Python √© compilado (T/F)?", "ML requer GPU (T/F)?"],
    "task": "tf"
  }
}
```

### Dados de Sa√≠da (CSV)
```
section,question,text,cluster,answer_relevancy,bert_similarity
qa,O que √© ML?,O que √© ML? Machine Learning...,0,0.95,0.92
tf,Python √© compilado (T/F)?,Python √© compilado (T/F)?,1,0.88,0.85
```

---

## üîß Configura√ß√µes Comuns

### Alterar Modelo de Embedding
```python
# No seu c√≥digo
from sentence_transformers import SentenceTransformer

# Modelo r√°pido (recomendado para come√ßar)
model = SentenceTransformer("all-MiniLM-L6-v2")

# Modelo mais preciso
model = SentenceTransformer("all-mpnet-base-v2")

# Modelo multil√≠ngue
model = SentenceTransformer("paraphrase-multilingual-mpnet-base-v2")
```

### Ajustar N√∫mero de Clusters
```python
from utils.run import kmeans_model

# Testar diferentes Ks
for k in [3, 5, 10, 15, 20]:
    df, model = kmeans_model(chosen_k=k)
    print(f"K={k}: {len(df)} pontos")
```

### Salvar Resultados
```python
# CSV
df.to_csv("meus_clusters.csv", index=False)

# TXT (um arquivo por cluster)
from utils.utils_IO import save_txt_per_cluster
save_txt_per_cluster(df, "./output/clusters", "text")
```

---

## üêõ Problemas Comuns

### ‚ùå "ModuleNotFoundError: No module named 'utils'"
**‚úÖ Solu√ß√£o**: Certifique-se de executar do diret√≥rio raiz
```bash
cd Clustering-Analysis-Pipeline
python seu_script.py  # ‚úì Correto
```

### ‚ùå "No such file or directory"
**‚úÖ Solu√ß√£o**: Configure `.env` com caminhos corretos
```bash
cat .env  # Verify paths
```

### ‚ùå "CUDA out of memory"
**‚úÖ Solu√ß√£o**: Use modelo menor de embedding
```python
model = SentenceTransformer("all-MiniLM-L6-v2")  # Mais leve
```

### ‚ùå "AWS credentials not configured"
**‚úÖ Solu√ß√£o**: Configure vari√°veis AWS em `.env`
```bash
export AWS_KEY_ID="sua_chave"
export AWS_SECRET_KEY="sua_senha"
```

---

## üìö Pr√≥ximos Passos

### 1. Explore os Exemplos
```bash
# Abrir notebook principal
jupyter notebook Clustering_Analysis_Pipeline.ipynb
```

### 2. Leia a Documenta√ß√£o Completa
- [README.md](README.md) - Documenta√ß√£o detalhada
- [CONTRIBUTING.md](CONTRIBUTING.md) - Como contribuir
- [API Reference](docs/API.md) - Refer√™ncia de fun√ß√µes

### 3. Experimente com Seus Dados
```python
from utils.utils_IO import json_to_df
from utils.run import kmeans_model

# Carregar seus dados
df_input = json_to_df("seu_arquivo.json")

# Executar clustering
df_result, model = kmeans_model(chosen_k=10)

# Explorar resultados
print(df_result.groupby('cluster').size())
```

---

## üöÄ Dicas Pro

### 1. Analise a Qualidade dos Clusters
```python
# Ver distribui√ß√£o
print(df['cluster'].value_counts().sort_index())

# Ver m√©tricas
print(df.groupby('cluster')['score'].agg(['mean', 'std']))
```

### 2. Customize a Avalia√ß√£o
```python
# Criar m√©trica customizada
df['custom_metric'] = df['answer_relevancy'] * 0.7 + df['bert_similarity'] * 0.3
```

### 3. Combine M√©todos
```python
# K-Means para segmenta√ß√£o inicial
df_kmeans, _ = kmeans_model(5)

# Hierarchical para an√°lise profunda
df_hier, _ = hierarchical_clustering_bottom_top(5)

# Comparar
print(f"K-Means: {df_kmeans['cluster'].nunique()} clusters")
print(f"Hierarchical: {df_hier['cluster'].nunique()} clusters")
```

---

## üìß Precisa de Ajuda?

- üîç [Issues no GitHub](https://github.com/ArthurFachel/Clustering-Analysis-Pipeline/issues)
- üìñ [Documenta√ß√£o Completa](README.md)
- üí¨ [Discuss√µes](https://github.com/ArthurFachel/Clustering-Analysis-Pipeline/discussions)

---

## ‚ú® O Que Testar A Seguir?

- [ ] Rodar com seus pr√≥prios dados JSON
- [ ] Comparar os 3 m√©todos de clustering
- [ ] Ajustar n√∫mero de clusters
- [ ] Exportar resultados em CSV
- [ ] Usar diferentes modelos de embedding
- [ ] Avaliar com suas m√©tricas custom
- [ ] Gerar resumos de clusters via AWS

Feliz clustering! üéâ
