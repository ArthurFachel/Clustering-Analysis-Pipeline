# Clustering Analysis Pipeline

Uma pipeline completa e robusta para anÃ¡lise de clustering de dados textuais usando mÃºltiplos algoritmos de aprendizado nÃ£o-supervisionado. Este projeto implementa, compara e avalia trÃªs principais mÃ©todos de clustering: K-Means, Hierarchical Clustering (Bottom-up) e Hierarchical Clustering (Top-down).

## ğŸ“‹ VisÃ£o Geral

O Clustering Analysis Pipeline Ã© uma soluÃ§Ã£o integrada para:
- **Processamento de Dados**: Leitura e preparaÃ§Ã£o de dados de mÃºltiplas fontes JSON
- **GeraÃ§Ã£o de Embeddings**: Utiliza modelos de transformers para criar representaÃ§Ãµes vetoriais de textos
- **Clustering AutomÃ¡tico**: Implementa trÃªs algoritmos diferentes de clustering
- **AvaliaÃ§Ã£o Abrangente**: Calcula mÃºltiplas mÃ©tricas de qualidade dos clusters
- **AnÃ¡lise Agregada**: Consolida resultados de mÃºltiplos modelos para comparaÃ§Ã£o

## âœ¨ CaracterÃ­sticas Principais

- âœ… **MÃºltiplos Algoritmos**: K-Means, Agglomerative Clustering, Bisecting K-Means, HDBSCAN
- âœ… **Embeddings SemÃ¢nticos**: IntegraÃ§Ã£o com Sentence Transformers (all-MiniLM-L6-v2)
- âœ… **MÃ©tricas Multidimensionais**: 
  - Answer Relevancy
  - BERT Similarity
  - Correctness (GEval)
  - Prompt Alignment
- âœ… **AnÃ¡lise Comparativa**: Avalia mÃºltiplos modelos de IA simultaneamente
- âœ… **VisualizaÃ§Ã£o Gerada**: NomeaÃ§Ã£o automÃ¡tica de clusters via AWS/LLM
- âœ… **ExportaÃ§Ã£o FlexÃ­vel**: Resultados em CSV e TXT

## ğŸ”§ Requisitos

### Sistema
- Python 3.8+
- Linux/macOS/Windows
- 4GB+ de RAM (recomendado 8GB+)

### DependÃªncias Principais
- pandas >= 1.3.0
- scikit-learn >= 1.0.0
- sentence-transformers >= 2.0.0
- numpy >= 1.19.0
- python-dotenv >= 0.19.0
- boto3 (para integraÃ§Ã£o AWS)

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone o RepositÃ³rio
```bash
git clone https://github.com/ArthurFachel/Clustering-Analysis-Pipeline.git
cd Clustering-Analysis-Pipeline
```

### 2. Crie um Ambiente Virtual
```bash
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate
```

### 3. Instale as DependÃªncias
```bash
pip install -r requirements.txt
```

### 4. Configure as VariÃ¡veis de Ambiente
```bash
cp .env.example .env
```

Edite o arquivo `.env` e defina:
```env
JSON_PATH="/caminho/para/seus/dados.json"
FOLDER_PATH="/caminho/para/pasta/modelos"
AWS_REGION="us-east-1"
AWS_KEY_ID="sua_chave_aws"
AWS_SECRET_KEY="sua_senha_aws"
```

## ğŸ“ Estrutura do Projeto

```
Clustering-Analysis-Pipeline/
â”œâ”€â”€ Clustering_Analysis_Pipeline.ipynb  # Notebook principal
â”œâ”€â”€ README.md                           # Este arquivo
â”œâ”€â”€ requirements.txt                    # DependÃªncias Python
â”œâ”€â”€ .env                                # VariÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                          # Arquivos ignorados
â””â”€â”€ utils/                              # MÃ³dulos utilitÃ¡rios
    â”œâ”€â”€ run.py                          # ImplementaÃ§Ã£o dos algoritmos
    â”œâ”€â”€ evaluation.py                   # FunÃ§Ãµes de avaliaÃ§Ã£o
    â”œâ”€â”€ metrics.py                      # CÃ¡lculo de mÃ©tricas
    â”œâ”€â”€ aglomerar.py                    # AgregaÃ§Ã£o de dados
    â”œâ”€â”€ assign.py                       # AtribuiÃ§Ã£o de clusters
    â”œâ”€â”€ utils_IO.py                     # Entrada/saÃ­da
    â””â”€â”€ AWS.py                          # IntegraÃ§Ã£o AWS
```

## ğŸš€ Como Usar

### ExecuÃ§Ã£o BÃ¡sica

Execute o notebook principal:
```bash
jupyter notebook Clustering_Analysis_Pipeline.ipynb
```

### ExecuÃ§Ã£o por Script

```python
from utils.run import kmeans_model, hierarchical_clustering_bottom_top, hierarchical_clustering_top_bottom
import os
from dotenv import load_dotenv

load_dotenv()

# K-Means Clustering
df_kmeans, model = kmeans_model(chosen_k=5)

# Hierarchical (Bottom-Top)
df_bottom_top, model = hierarchical_clustering_bottom_top(chosen_k=5)

# Hierarchical (Top-Down)
df_top_down, model = hierarchical_clustering_top_down(chosen_k=5)
```

### AvaliaÃ§Ã£o de Resultados

```python
from utils.evaluation import evaluate_kmeans, evaluate_top, evaluate_bottom

# Avaliar K-Means
results_kmeans = evaluate_kmeans(models_folder="/path/to/models", i=5)
results_kmeans.to_csv("kmeans_evaluation_5.csv", index=False)

# Avaliar Top-Down
results_top = evaluate_top(models_folder="/path/to/models", i=5)
results_top.to_csv("top_down_evaluation_5.csv", index=False)
```

## ğŸ§  Algoritmos de Clustering

### 1. K-Means
- **DescriÃ§Ã£o**: Particiona dados em k clusters baseado em centrÃ³ides
- **Vantagens**: RÃ¡pido, escalÃ¡vel, interpretÃ¡vel
- **Desvantagens**: Requer predefiniÃ§Ã£o de k, sensÃ­vel a outliers
- **Uso Ideal**: Dados bem separados, clusters de tamanho similar

### 2. Hierarchical Clustering (Agglomerative)
- **DescriÃ§Ã£o**: Cria Ã¡rvore de clusters atravÃ©s de merging bottom-up
- **Variantes**:
  - **Bottom-Top**: ComeÃ§a com cada ponto como cluster
  - **Top-Down**: ComeÃ§a com todos em um cluster, divide recursivamente
- **Vantagens**: DendrogrÃ¡fico interpretÃ¡vel, nÃ£o requer predefiniÃ§Ã£o de k
- **Desvantagens**: Computacionalmente mais custoso
- **Uso Ideal**: Dados hierÃ¡rquicos, exploraÃ§Ã£o de estrutura

### 3. HDBSCAN (com suporte)
- **DescriÃ§Ã£o**: Clustering hierÃ¡rquico baseado em densidade
- **Vantagens**: Detecta outliers, clusters de tamanhos variados
- **Desvantagens**: ParÃ¢metros sensÃ­veis, complexo
- **Uso Ideal**: Dados com clusters irregulares, presenÃ§a de ruÃ­do

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

### MÃ©tricas IncluÃ­das

| MÃ©trica | DescriÃ§Ã£o | Intervalo |
|---------|-----------|-----------|
| **Answer Relevancy** | QuÃ£o relevante Ã© a resposta ao prompt | 0-1 |
| **BERT Similarity** | Similaridade semÃ¢ntica via BERT | 0-1 |
| **Correctness (GEval)** | AvaliaÃ§Ã£o de corretude automÃ¡tica | 0-1 |
| **Prompt Alignment** | Alinhamento com o prompt original | 0-1 |

### CÃ¡lculo do Score Agregado

```python
scores = [answer_relevancy, bert_similarity, correctness_geval, prompt_alignment]
score_final = mean(scores_vÃ¡lidos)
```

## ğŸ“ˆ Formato de SaÃ­da

### CSV
```
model,task,cluster,num_questions,score_mean,score_sum,answer_relevancy_mean,...
```

### TXT (Cluster Summaries)
```
[cluster_id]_[resumo_ia]_.txt
```

Cada arquivo contÃ©m os textos do cluster nomeados automaticamente via AWS.

## ğŸ”Œ IntegraÃ§Ã£o AWS

Para gerar nomes descritivos automÃ¡ticos de clusters:

```python
from utils.AWS import generate

summary = generate("texto do cluster para sumarizar")
# Retorna: "GeraÃ§Ã£o de Embeddings, Aprendizado Profundo"
```

**ConfiguraÃ§Ã£o NecessÃ¡ria**:
- VariÃ¡veis de ambiente AWS configuradas
- PermissÃµes IAM apropriadas
- Credenciais AWS vÃ¡lidas

## ğŸ“ Exemplos de Uso

### Exemplo 1: Pipeline Completo

```python
from utils.utils_IO import json_to_df
from utils.run import kmeans_model

# Carregar dados
df_raw = json_to_df("data.json")

# Executar K-Means
for k in [3, 5, 10, 15]:
    df_result, model = kmeans_model(chosen_k=k)
    df_result.to_csv(f"results_kmeans_{k}.csv", index=False)
```

### Exemplo 2: ComparaÃ§Ã£o de MÃ©todos

```python
from utils.run import (
    kmeans_model,
    hierarchical_clustering_bottom_top,
    hierarchical_clustering_top_bottom
)

k = 10

results = {
    "kmeans": kmeans_model(k)[0],
    "bottom_top": hierarchical_clustering_bottom_top(k)[0],
    "top_bottom": hierarchical_clustering_top_bottom(k)[0]
}

# AnÃ¡lise comparativa
for method, df in results.items():
    print(f"{method}: {len(df)} pontos")
```

### Exemplo 3: AnÃ¡lise Agregada

```python
from utils.aglomerar import aglomerar
from utils.assign import assign_clusters
from utils.metrics import compute_score

# Agregar dados de mÃºltiplos modelos
df = aglomerar("/path/to/model/results")

# Atribuir clusters
df = assign_clusters(df, embed_model, clustering_model)

# Computar scores
df["score"] = df.apply(compute_score, axis=1)

# Resumir por cluster
summary = (
    df
    .groupby(["model", "task", "cluster"], as_index=False)
    .agg({
        "score": ["mean", "std", "count"],
        "answer_relevancy": "mean",
        "bert_similarity": "mean"
    })
)
```

## ğŸ”„ Fluxo de Trabalho TÃ­pico

```mermaid
graph TD
    A[Dados JSON] --> B[Limpeza de Dados]
    B --> C[GeraÃ§Ã£o de Embeddings]
    C --> D{Escolher Algoritmo}
    D -->|K-Means| E1[Clustering K-Means]
    D -->|Hierarchical| E2[Clustering HierÃ¡rquico]
    D -->|HDBSCAN| E3[Clustering HDBSCAN]
    E1 --> F[AvaliaÃ§Ã£o de MÃ©tricas]
    E2 --> F
    E3 --> F
    F --> G[AgregaÃ§Ã£o de Resultados]
    G --> H[GeraÃ§Ã£o de Nomes via AWS]
    H --> I[ExportaÃ§Ã£o CSV/TXT]
```

## ğŸ§ª Testes

Para testar a pipeline:

```bash
# Teste bÃ¡sico de importaÃ§Ã£o
python -c "from utils.run import kmeans_model; print('âœ“ Pipeline importada com sucesso')"

# Teste com dados de exemplo
python examples/test_clustering.py
```

## ğŸ“Š Datasets Suportados

### Formato JSON
```json
{
  "section_name": {
    "question": ["pergunta1", "pergunta2"],
    "answer": ["resposta1", "resposta2"],
    "task": "qa"
  }
}
```

### Formato Interno Esperado
```
section | question | text | cluster | score | answer_relevancy | ...
```

## ğŸ› Troubleshooting

### Erro: "ModuleNotFoundError: No module named 'utils'"
**SoluÃ§Ã£o**: Execute a partir do diretÃ³rio raiz do projeto
```bash
cd Clustering-Analysis-Pipeline
jupyter notebook
```

### Erro: "AWS credentials not found"
**SoluÃ§Ã£o**: Configure as variÃ¡veis de ambiente
```bash
export AWS_KEY_ID="sua_chave"
export AWS_SECRET_KEY="sua_senha"
```

### Erro: "CUDA out of memory"
**SoluÃ§Ã£o**: Reduza batch size no `utils_IO.py` ou use GPU com maior memÃ³ria

### Embedding muito lento
**SoluÃ§Ã£o**: Use modelo mais leve ou reduza dataset
```python
# Alternativa mais rÃ¡pida
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("all-MiniLM-L6-v2")  # Fast
# vs
model = SentenceTransformer("all-mpnet-base-v2")  # Mais lento mas melhor
```

## ğŸ“š ReferÃªncias e DocumentaÃ§Ã£o

- [Sentence Transformers](https://www.sbert.net/)
- [Scikit-learn Clustering](https://scikit-learn.org/stable/modules/clustering.html)
- [AWS Bedrock](https://aws.amazon.com/bedrock/)
- [DeepEval Metrics](https://github.com/confident-ai/deepeval)

## ğŸ“„ Estrutura de DiretÃ³rios de SaÃ­da

```
results/
â”œâ”€â”€ K_Means/
â”‚   â”œâ”€â”€ clusters/
â”‚   â”‚   â”œâ”€â”€ 0_cluster_name.txt
â”‚   â”‚   â””â”€â”€ 1_cluster_name.txt
â”‚   â”œâ”€â”€ csv/
â”‚   â”‚   â””â”€â”€ kmeans_results.csv
â”‚   â””â”€â”€ plots/
â”œâ”€â”€ Hierarchical/
â”‚   â”œâ”€â”€ Top-Bottom/
â”‚   â””â”€â”€ Bottom-Top/
â””â”€â”€ HDBSCAN/
    â”œâ”€â”€ clusters/
    â”œâ”€â”€ csv/
    â””â”€â”€ plots/
```

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. FaÃ§a um Fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ Changelog

### v1.0.0 (28/12/2024)
- âœ¨ Release inicial
- ğŸ¯ ImplementaÃ§Ã£o de K-Means, Hierarchical Clustering, HDBSCAN
- ğŸ“Š Sistema de mÃ©tricas multidimensionais
- ğŸ”Œ IntegraÃ§Ã£o AWS para nomeaÃ§Ã£o de clusters
- ğŸ“ˆ Pipelines de avaliaÃ§Ã£o e agregaÃ§Ã£o

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ‘¨â€ğŸ’» Autor

**Arthur Fachel**  
GitHub: [@ArthurFachel](https://github.com/ArthurFachel)

## ğŸ“§ Contato e Suporte

Para dÃºvidas, sugestÃµes ou relatÃ³rio de bugs:
- ğŸ“¬ Abra uma issue no GitHub
- ğŸ“§ Entre em contato via GitHub

## ğŸ™ Agradecimentos

- Comunidade Scikit-learn
- Hugging Face por Sentence Transformers
- AWS por Bedrock
- Comunidade DeepEval

---

**Ãšltima atualizaÃ§Ã£o**: Fevereiro, 2026